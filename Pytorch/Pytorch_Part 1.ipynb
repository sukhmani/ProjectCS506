{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7638e14",
   "metadata": {},
   "source": [
    "<h1> CS506 Programming for Computing </h1>\n",
    "<h2> Pytorch Tutorial </h2>\n",
    "<h3> Team Members: Sukhmani Thukral,  Lanxi Luo, Shruti Arvind Kherade <h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe80398",
   "metadata": {},
   "source": [
    "This tutorial provides a comprehensive guide to using PyTorch for image classification on the MNIST dataset. You'll learn how to work with tensors, load and transform data, define neural networks, and train models using `torch.autograd`. The MNIST dataset consists of 70,000 grayscale images of handwritten digits (0â€“9), each of size 28x28 pixels.\n",
    "\n",
    "Topics we will cover:\n",
    "- Introduction to PyTorch and its Applications\n",
    "- Tensors\n",
    "- Autograd and Gradients\n",
    "- Datasets and Data Loading\n",
    "- Transforms\n",
    "- Brief Introduction to Neural Network\n",
    "- Building Neural Network\n",
    "- Training Neural Network using torch.autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5960bffc",
   "metadata": {},
   "source": [
    "# (1) Introduction to PyTorch and its Applications\n",
    "\n",
    "PyTorch is a popular open-source deep learning framework developed by Facebook's AI Research lab. It provides a flexible and efficient platform for building and training neural networks, making it popular among researchers and practitioners in machine learning and artificial intelligence.\n",
    "\n",
    "## Key Features of PyTorch\n",
    "- **Dynamic Computation Graphs:** PyTorch uses dynamic computation graphs (also known as define-by-run), allowing for more flexibility during model development and debugging.\n",
    "- **Tensor Computation:** PyTorch offers a powerful N-dimensional array (tensor) library, similar to NumPy, with strong GPU acceleration.\n",
    "- **Automatic Differentiation:** The `autograd` module automatically computes gradients, simplifying the process of backpropagation in neural networks.\n",
    "- **Extensive Libraries:** PyTorch includes libraries for vision (`torchvision`), text (`torchtext`), and audio (`torchaudio`) tasks.\n",
    "\n",
    "## Applications of PyTorch\n",
    "PyTorch is widely used in various domains, including:\n",
    "- **Computer Vision:** Image classification, object detection, segmentation, and style transfer.\n",
    "- **Natural Language Processing (NLP):** Text classification, sentiment analysis, machine translation, and language modeling.\n",
    "- **Reinforcement Learning:** Training agents for games, robotics, and decision-making tasks.\n",
    "- **Generative Models:** Building GANs (Generative Adversarial Networks) and VAEs (Variational Autoencoders).\n",
    "- **Scientific Computing:** Simulations, time-series forecasting, and other research applications.\n",
    "\n",
    "PyTorch's ease of use, strong community support, and integration with Python make it a preferred choice for both academic research and industry applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f94c60",
   "metadata": {},
   "source": [
    "## (2) Tensors\n",
    "Tensors are the fundamental data structures in PyTorch, similar to NumPy arrays but with powerful GPU acceleration and gradient tracking capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236c973f",
   "metadata": {},
   "source": [
    "### Tensor Creation\n",
    "You can create tensors from Python lists or using built-in PyTorch methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5990ecbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a: tensor([1., 2., 3.])\n",
      "Tensor b: tensor([4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Creating tensors\n",
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.tensor([4.0, 5.0, 6.0])\n",
    "print(\"Tensor a:\", a)\n",
    "print(\"Tensor b:\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aeb298",
   "metadata": {},
   "source": [
    "### Arithmetic Operations\n",
    "Tensors support standard arithmetic operations like addition, subtraction, multiplication, and dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2829df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition: tensor([5., 7., 9.])\n",
      "Dot product: tensor(32.)\n"
     ]
    }
   ],
   "source": [
    "print(\"Addition:\", a + b)\n",
    "print(\"Dot product:\", torch.dot(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6564ae9e",
   "metadata": {},
   "source": [
    "### Shape and Data Types\n",
    "Tensors have attributes for checking their shape and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb78cac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a: torch.Size([3])\n",
      "Data type of a: torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of a:\", a.shape)\n",
    "print(\"Data type of a:\", a.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a2cc5f",
   "metadata": {},
   "source": [
    "## (3) Autograd and Gradients\n",
    "PyTorch uses `autograd` to automatically compute gradients. This is useful for training neural networks using backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531950dd",
   "metadata": {},
   "source": [
    "### requires_grad\n",
    "To track operations on tensors for automatic differentiation, set `requires_grad=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aeb9634",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y = torch.tensor([4.0, 5.0, 6.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8adc52a",
   "metadata": {},
   "source": [
    "### .backward()\n",
    "Computes the gradients of a scalar output with respect to input tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de47065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.dot(x, y)\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac4b6bc",
   "metadata": {},
   "source": [
    "### Accessing .grad\n",
    "Once `.backward()` is called, you can access the gradient using the `.grad` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68f2fe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of x: None\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient of x:\", x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "273200b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D Tensor: tensor([1., 2., 3.])\n",
      "2D Tensor:\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "Tensor of zeros:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Tensor of ones:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "Addition: tensor([5, 7, 9])\n",
      "Element-wise multiplication: tensor([ 4, 10, 18])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Introduction to Tensors\n",
    "\n",
    "\n",
    "# Tensors are multi-dimensional arrays, similar to NumPy arrays, but with GPU acceleration and automatic differentiation support.\n",
    "# Example: Creating a 1D tensor\n",
    "tensor_1d = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(\"1D Tensor:\", tensor_1d)\n",
    "\n",
    "# Example: Creating a 2D tensor (matrix)\n",
    "tensor_2d = torch.tensor([[1, 2], [3, 4]])\n",
    "print(\"2D Tensor:\\n\", tensor_2d)\n",
    "\n",
    "# Tensors can be created from lists, NumPy arrays, or using built-in functions like torch.zeros, torch.ones, etc.\n",
    "tensor_zeros = torch.zeros((2, 3))\n",
    "print(\"Tensor of zeros:\\n\", tensor_zeros)\n",
    "\n",
    "tensor_ones = torch.ones((2, 3))\n",
    "print(\"Tensor of ones:\\n\", tensor_ones)\n",
    "\n",
    "# Tensors support various operations: addition, multiplication, reshaping, etc.\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "print(\"Addition:\", a + b)\n",
    "print(\"Element-wise multiplication:\", a * b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4364fe69",
   "metadata": {},
   "source": [
    "## (4) Datasets and Data Loading\n",
    "PyTorch uses `torchvision.datasets` and `DataLoader` to handle data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b555eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.22.1)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from torchvision) (2.2.4)\n",
      "Requirement already satisfied: torch==2.7.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torchvision) (2.7.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (76.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.7.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch==2.7.1->torchvision) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
    "test_data = datasets.MNIST(root=\"data\", train=False, download=True, transform=ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd16817b",
   "metadata": {},
   "source": [
    "## (5) Transforms\n",
    "We normalize the dataset to have zero mean and unit variance. This helps the network converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf97965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /home/codespace/.python/current/lib/python3.12/site-packages (0.22.1)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from torchvision) (2.2.4)\n",
      "Requirement already satisfied: torch==2.7.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from torchvision) (2.7.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (76.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.7.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch==2.7.1->torchvision) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchvision\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3b5f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data:\n",
      "   Animal  Weight  Color\n",
      "0     cat     4.0  black\n",
      "1     dog    20.0  brown\n",
      "2  rabbit     2.0  white\n",
      "3     cat     5.0  white\n",
      "4     dog    22.0  black\n",
      "5  rabbit     2.5  brown\n",
      "6     cat     4.5  brown\n",
      "7     dog    21.0  white\n",
      "8  rabbit     3.0  black\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.00      0.00      0.00         0\n",
      "         dog       0.00      0.00      0.00         2\n",
      "      rabbit       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.33      0.33      0.33         3\n",
      "weighted avg       0.33      0.33      0.33         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Step 2: Load the animal dataset \n",
    "\n",
    "data = {\n",
    "    'Animal': ['cat', 'dog', 'rabbit', 'cat', 'dog', 'rabbit', 'cat', 'dog', 'rabbit'],\n",
    "    'Weight': [4, 20, 2, 5, 22, 2.5, 4.5, 21, 3],\n",
    "    'Color': ['black', 'brown', 'white', 'white', 'black', 'brown', 'brown', 'white', 'black']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Sample Data:\")\n",
    "print(df)\n",
    "\n",
    "# Step 3: Encode categorical variables\n",
    "le_color = LabelEncoder()\n",
    "df['Color_encoded'] = le_color.fit_transform(df['Color'])\n",
    "le_animal = LabelEncoder()\n",
    "df['Animal_encoded'] = le_animal.fit_transform(df['Animal'])\n",
    "\n",
    "# Step 4: Prepare features and target\n",
    "X = df[['Weight', 'Color_encoded']]\n",
    "y = df['Animal_encoded']\n",
    "\n",
    "# Step 5: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 6: Train a classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Make predictions and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le_animal.classes_))\n",
    "\n",
    "# Explanation:\n",
    "# - We created a sample animal dataset with features 'Weight' and 'Color'.\n",
    "# - Used LabelEncoder to convert categorical data to numeric.\n",
    "# - Split the data into training and testing sets.\n",
    "# - Trained a RandomForestClassifier for multi-class classification.\n",
    "# - Evaluated the model using a classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688327da",
   "metadata": {},
   "source": [
    "Pytorch for Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61acb43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model predictions: [1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Example: Simple sentiment classification with PyTorch\n",
    "\n",
    "# Sample data (toy example)\n",
    "sentences = [\"I love PyTorch\", \"PyTorch is great\", \"I dislike bugs\", \"Bugs are annoying\"]\n",
    "labels = [1, 1, 0, 0]  # 1: positive, 0: negative\n",
    "\n",
    "# Build vocabulary\n",
    "vocab = set(word for sent in sentences for word in sent.lower().split())\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "\n",
    "# Encode sentences as bag-of-words vectors\n",
    "def encode(sentence):\n",
    "    vec = torch.zeros(len(vocab))\n",
    "    for word in sentence.lower().split():\n",
    "        vec[word2idx[word]] += 1\n",
    "    return vec\n",
    "\n",
    "X = torch.stack([encode(s) for s in sentences])\n",
    "y = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Simple model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(len(vocab), 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X)\n",
    "    loss = criterion(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Trained model predictions:\", (model(X) > 0.5).int().squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d67a16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings for '['i', 'love', 'pytorch']':\n",
      "tensor([[ 1.2678,  0.8066, -0.6511,  0.9877,  0.0681],\n",
      "        [ 1.1497, -0.2470, -1.0230, -0.3671,  3.0108],\n",
      "        [ 0.0067, -1.2524,  0.7639,  1.0786,  0.7947]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Create an embedding layer for the vocabulary\n",
    "embedding_dim = 5  # You can choose any embedding size\n",
    "embedding = nn.Embedding(num_embeddings=len(vocab), embedding_dim=embedding_dim)\n",
    "\n",
    "# Example: Get embeddings for each word in a sentence\n",
    "sample_sentence = sentences[0].lower().split()  # e.g., \"I love PyTorch\"\n",
    "indices = torch.tensor([word2idx[word] for word in sample_sentence])\n",
    "\n",
    "embedded_words = embedding(indices)\n",
    "print(\"Word embeddings for '{}':\\n{}\".format(sample_sentence, embedded_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cbf755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple feedforward neural network for NLP (Bag-of-Words input)\n",
    "class SimpleNLPModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SimpleNLPModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len)\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_len, embedding_dim)\n",
    "        pooled = embedded.mean(dim=1)  # Average pooling over sequence\n",
    "        out = self.fc(pooled)\n",
    "        return self.sigmoid(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eba8d10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: tensor([[0.6169]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "model = SimpleNLPModel(vocab_size=len(vocab), embedding_dim=embedding_dim)\n",
    "output = model(indices.unsqueeze(0))  # indices: tensor of word indices for a sentence\n",
    "print(\"Model output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0e19c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM model predictions: [1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# Example LSTM-based sentiment analysis model\n",
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(SentimentLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  # (batch, seq_len, embedding_dim)\n",
    "        lstm_out, _ = self.lstm(embedded)  # (batch, seq_len, hidden_dim)\n",
    "        out = lstm_out[:, -1, :]  # Take the output of the last time step\n",
    "        out = self.fc(out)\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "# Prepare input: convert sentences to sequences of word indices\n",
    "max_len = max(len(s.split()) for s in sentences)\n",
    "def encode_sequence(sentence, word2idx, max_len):\n",
    "    idxs = [word2idx[word] for word in sentence.lower().split()]\n",
    "    # Pad with zeros if shorter than max_len\n",
    "    idxs += [0] * (max_len - len(idxs))\n",
    "    return torch.tensor(idxs)\n",
    "\n",
    "X_seq = torch.stack([encode_sequence(s, word2idx, max_len) for s in sentences])\n",
    "y_seq = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Instantiate and train the model\n",
    "hidden_dim = 8\n",
    "output_dim = 1\n",
    "lstm_model = SentimentLSTM(vocab_size=len(vocab), embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "lstm_criterion = nn.BCELoss()\n",
    "lstm_optimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    lstm_optimizer.zero_grad()\n",
    "    outputs = lstm_model(X_seq)\n",
    "    loss = lstm_criterion(outputs, y_seq)\n",
    "    loss.backward()\n",
    "    lstm_optimizer.step()\n",
    "\n",
    "print(\"LSTM model predictions:\", (lstm_model(X_seq) > 0.5).int().squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eca7df08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i love pytorch', 'pytorch is great', 'i dislike bugs', 'bugs are annoying']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and non-alphabetic characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Example: preprocess all sentences\n",
    "preprocessed_sentences = [preprocess_text(s) for s in sentences]\n",
    "print(preprocessed_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30fb3ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: I love PyTorch\n",
      "Cleaned: i love pytorch\n",
      "Tokens: ['i', 'love', 'pytorch']\n",
      "\n",
      "Original: PyTorch is great\n",
      "Cleaned: pytorch is great\n",
      "Tokens: ['pytorch', 'is', 'great']\n",
      "\n",
      "Original: I dislike bugs\n",
      "Cleaned: i dislike bugs\n",
      "Tokens: ['i', 'dislike', 'bugs']\n",
      "\n",
      "Original: Bugs are annoying\n",
      "Cleaned: bugs are annoying\n",
      "Tokens: ['bugs', 'are', 'annoying']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Text Preprocessing Explanation\n",
    "\n",
    "# Text preprocessing is a crucial step in Natural Language Processing (NLP) tasks.\n",
    "# It typically includes:\n",
    "# 1. Cleaning: Removing punctuation, converting text to lowercase, and eliminating unwanted characters.\n",
    "# 2. Tokenization: Splitting sentences into individual words or tokens.\n",
    "# 3. Vectorization: Converting words or tokens into numerical representations (such as indices or embeddings) that can be used by machine learning models.\n",
    "\n",
    "# Example using the preprocess_text function and tokenization:\n",
    "for sentence in sentences:\n",
    "    cleaned = preprocess_text(sentence)\n",
    "    tokens = cleaned.split()\n",
    "    print(f\"Original: {sentence}\")\n",
    "    print(f\"Cleaned: {cleaned}\")\n",
    "    print(f\"Tokens: {tokens}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99a28aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded input tensor:\n",
      " tensor([[3, 0, 5],\n",
      "        [5, 7, 1],\n",
      "        [3, 6, 4],\n",
      "        [4, 2, 8]])\n"
     ]
    }
   ],
   "source": [
    "# Standardize the token lengths of each review for consistency\n",
    "\n",
    "# Find the maximum sequence length\n",
    "max_seq_len = max(len(s.split()) for s in sentences)\n",
    "\n",
    "# Function to encode and pad/truncate each sentence to max_seq_len\n",
    "def encode_and_pad(sentence, word2idx, max_len):\n",
    "    idxs = [word2idx[word] for word in sentence.lower().split()]\n",
    "    # Pad with zeros if shorter, or truncate if longer\n",
    "    if len(idxs) < max_len:\n",
    "        idxs += [0] * (max_len - len(idxs))\n",
    "    else:\n",
    "        idxs = idxs[:max_len]\n",
    "    return torch.tensor(idxs)\n",
    "\n",
    "# Apply to all sentences\n",
    "X_padded = torch.stack([encode_and_pad(s, word2idx, max_seq_len) for s in sentences])\n",
    "print(\"Padded input tensor:\\n\", X_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "116a62f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(SentimentLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  # (batch, seq_len, embedding_dim)\n",
    "        lstm_out, _ = self.lstm(embedded)  # (batch, seq_len, hidden_dim)\n",
    "        out = lstm_out[:, -1, :]  # Take the output of the last time step\n",
    "        out = self.fc(out)\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a46389db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define dataset transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define the NLP model\n",
    "class SimpleNLPModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(SimpleNLPModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()  # Required for BCELoss\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x.long())  # Ensure LongTensor for embedding lookup\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "# Initialize model, loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c320c71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "# Evaluate the LSTM model's performance on the validation dataset (X_seq, y_seq)\n",
    "lstm_model.eval()\n",
    "with torch.no_grad():\n",
    "    val_outputs = lstm_model(X_seq)\n",
    "    val_predictions = (val_outputs > 0.5).float()\n",
    "    accuracy = (val_predictions == y_seq).float().mean().item()\n",
    "    print(f\"Validation Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "260a7326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def predict_sentiment(text, model, word2idx, max_len):\n",
    "    # Preprocess the input text\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Tokenize and encode\n",
    "    tokens = text.split()\n",
    "    idxs = [word2idx.get(word, 0) for word in tokens]  # Use 0 for unknown words\n",
    "    # Pad or truncate to max_len\n",
    "    if len(idxs) < max_len:\n",
    "        idxs += [0] * (max_len - len(idxs))\n",
    "    else:\n",
    "        idxs = idxs[:max_len]\n",
    "    input_tensor = torch.tensor(idxs).unsqueeze(0)  # Shape: (1, max_len)\n",
    "    # Model prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        pred = (output > 0.5).item()\n",
    "    return \"Positive\" if pred else \"Negative\"\n",
    "\n",
    "# Example usage:\n",
    "# print(predict_sentiment(\"I love PyTorch\", lstm_model, word2idx, max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d7a9d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "print(predict_sentiment(\"I love PyTorch\", lstm_model, word2idx, max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb54571",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "# In this notebook, we explored the basics of PyTorch, including tensor operations, automatic differentiation, and building neural networks for both image and text data. \n",
    "# We demonstrated how to preprocess data, encode text, and train models for classification tasks using both simple and LSTM-based architectures.\n",
    "# The practical examples on the MNIST dataset and sentiment analysis provided hands-on experience with data loading, model definition, training, and evaluation.\n",
    "# With these foundational skills, you are now equipped to further explore deep learning applications using PyTorch for a variety of domains."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
